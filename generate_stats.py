#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–æ–±—Ä–∞–Ω–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É.
–°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª STATS.md —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É.
"""

import pandas as pd
from pathlib import Path
from collections import defaultdict
from datetime import datetime


def load_csv_safe(csv_path: Path, encoding='utf-8-sig'):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CSV —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤."""
    if not csv_path.exists():
        return None
    try:
        return pd.read_csv(csv_path, encoding=encoding)
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {csv_path.name}: {e}")
        return None


def generate_class_stats(df, class_name, attributes_to_track):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–ª–∞—Å—Å—É.

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞
        class_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
        attributes_to_track: –°–ø–∏—Å–æ–∫ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è

    Returns:
        str: Markdown —Ç–∞–±–ª–∏—Ü–∞ —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
    """
    if df is None or df.empty:
        return f"## {class_name}\n\n*–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö*\n\n"

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ container_name
    grouped = df.groupby('container_name', dropna=False)

    # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è container_name
    df_filled = df.copy()
    df_filled['container_name'] = df_filled['container_name'].fillna('(–Ω–µ —É–∫–∞–∑–∞–Ω–æ)')
    grouped = df_filled.groupby('container_name')

    stats_lines = [f"## {class_name}\n"]
    stats_lines.append(f"**–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:** {len(df)}\n")
    stats_lines.append(f"**–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∞—Ä:** {len(grouped)}\n")

    # –¢–∞–±–ª–∏—Ü–∞: container_name -> –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ –∫–∞–∂–¥–æ–º—É –∞—Ç—Ä–∏–±—É—Ç—É
    table_lines = ["| –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–∞—Ä—ã | –í—Å–µ–≥–æ |"]

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Ç—Ä–∏–±—É—Ç–∞
    for attr in attributes_to_track:
        if attr in df.columns:
            table_lines[0] += f" {attr} |"

    # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç–∞–±–ª–∏—Ü—ã
    separator = "|" + "-" * 15 + "|" + "-" * 7 + "|"
    for attr in attributes_to_track:
        if attr in df.columns:
            separator += "-" * (len(attr) + 2) + "|"
    table_lines.append(separator)

    # –î–∞–Ω–Ω—ã–µ –ø–æ –∫–∞–∂–¥–æ–º—É container_name
    for name, group in grouped:
        row = f"| {name} | {len(group)} |"

        for attr in attributes_to_track:
            if attr in df.columns:
                # –ü–æ–¥—Å—á–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–∞
                value_counts = group[attr].value_counts().to_dict()
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ "–∑–Ω–∞—á–µ–Ω–∏–µ: –∫–æ–ª-–≤–æ"
                if len(value_counts) == 0:
                    cell_content = "-"
                elif len(value_counts) == 1:
                    val, count = list(value_counts.items())[0]
                    cell_content = f"{val}" if count == len(group) else f"{val}:{count}"
                else:
                    # –ù–µ—Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ
                    parts = [f"{val}:{cnt}" for val, cnt in sorted(value_counts.items(), key=lambda x: -x[1])]
                    cell_content = ", ".join(parts)
                row += f" {cell_content} |"

        table_lines.append(row)

    stats_lines.extend(table_lines)
    stats_lines.append("\n")

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞—Ç—Ä–∏–±—É—Ç–∞–º
    stats_lines.append("### –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞—Ç—Ä–∏–±—É—Ç–∞–º\n")

    for attr in attributes_to_track:
        if attr in df.columns:
            value_counts = df[attr].value_counts()
            if not value_counts.empty:
                stats_lines.append(f"**{attr}:**")
                for val, count in value_counts.items():
                    percentage = (count / len(df)) * 100
                    stats_lines.append(f"  - {val}: {count} ({percentage:.1f}%)")
                stats_lines.append("")

    return "\n".join(stats_lines)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏."""

    dataset_dir = Path("dataset")
    stats_file = Path("STATS.md")

    print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞...")

    # –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–æ–≤
    pet_df = load_csv_safe(dataset_dir / "pet.csv")
    can_df = load_csv_safe(dataset_dir / "can.csv")
    foreign_df = load_csv_safe(dataset_dir / "foreign.csv")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É
    # –ü–æ—Ä—è–¥–æ–∫ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    pet_attrs = ['deformation', 'fill', 'transparency', 'label', 'volume', 'wet', 'condensate', 'glare', 'dirt']
    can_attrs = ['deformation', 'fill', 'finish', 'decoration', 'volume', 'wet', 'glare', 'label_attached', 'dirt']
    foreign_attrs = ['subtype', 'is_container', 'material', 'multiple_items']

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è markdown
    output = []
    output.append("# üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n")
    output.append(f"*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n")
    output.append("---\n")

    # PET —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if pet_df is not None:
        print(f"  ‚úì PET: {len(pet_df)} –∑–∞–ø–∏—Å–µ–π")
        output.append(generate_class_stats(pet_df, "PET ‚Äî –ü–ª–∞—Å—Ç–∏–∫–æ–≤—ã–µ –±—É—Ç—ã–ª–∫–∏", pet_attrs))
    else:
        print("  - PET: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        output.append("## PET ‚Äî –ü–ª–∞—Å—Ç–∏–∫–æ–≤—ã–µ –±—É—Ç—ã–ª–∫–∏\n\n*–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö*\n\n")

    output.append("---\n")

    # CAN —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if can_df is not None:
        print(f"  ‚úì CAN: {len(can_df)} –∑–∞–ø–∏—Å–µ–π")
        output.append(generate_class_stats(can_df, "CAN ‚Äî –ê–ª—é–º–∏–Ω–∏–µ–≤—ã–µ –±–∞–Ω–∫–∏", can_attrs))
    else:
        print("  - CAN: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        output.append("## CAN ‚Äî –ê–ª—é–º–∏–Ω–∏–µ–≤—ã–µ –±–∞–Ω–∫–∏\n\n*–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö*\n\n")

    output.append("---\n")

    # FOREIGN —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if foreign_df is not None:
        print(f"  ‚úì FOREIGN: {len(foreign_df)} –∑–∞–ø–∏—Å–µ–π")
        output.append(generate_class_stats(foreign_df, "FOREIGN ‚Äî –ü–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ –æ–±—ä–µ–∫—Ç—ã", foreign_attrs))
    else:
        print("  - FOREIGN: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        output.append("## FOREIGN ‚Äî –ü–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ –æ–±—ä–µ–∫—Ç—ã\n\n*–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö*\n\n")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
    with open(stats_file, 'w', encoding='utf-8') as f:
        f.write("".join(output))

    print(f"\n‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {stats_file}")


if __name__ == "__main__":
    main()
